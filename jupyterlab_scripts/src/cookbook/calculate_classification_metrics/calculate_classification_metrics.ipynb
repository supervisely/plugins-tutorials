{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Classification metrics\n",
    "A ready-to-use script to find classification metrics for class pairs\n",
    "\n",
    "**Input**:\n",
    "- Existing project labeled with both ground truth and predicted categories encoded as tags.\n",
    "- At least one pair of corresponding ground truth and prediction classes, e.g. (\"car_gt\", \"car_predicted\").\n",
    "\n",
    "**Output**:\n",
    "- Classification metrics for each class pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervisely_lib as sly\n",
    "import os\n",
    "import collections\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Edit the following settings for your own case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this field to the name of your team, where target workspace exists.\n",
    "team_name = \"jupyter_tutorials\"\n",
    "\n",
    "# Change this field to the of your workspace, where target project exists.\n",
    "workspace_name = \"metrics_tutorials\"\n",
    "\n",
    "# Change this field to the name of your target project.\n",
    "project_name = \"classification_metrics_demo_project\"\n",
    "\n",
    "# Configure the following dictionary so that is will match pairs of ground truth and predicted classes\n",
    "# for which the metrics will be caluclated.\n",
    "tags_mapping = {\n",
    "    \"kiwi\": \"kiwi_pred\",\n",
    "    \"lemon\": \"lemon_pred\",    \n",
    "}\n",
    "\n",
    "# If you are running this notebook on a Supervisely web instance, the connection\n",
    "# Edit those values if you run this notebook on your own PC\n",
    "# details below will be filled in from environment variables automatically.\n",
    "#\n",
    "# If you are running this notebook locally on your own machine, edit to fill in the\n",
    "# connection details manually. You can find your access token at\n",
    "# \"Your name on the top right\" -> \"Account settings\" -> \"API token\".\n",
    "address = os.environ['SERVER_ADDRESS']\n",
    "token = os.environ['API_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script setup\n",
    "\n",
    "Import nessesary packages and initialize Supervisely API to remotely manage your projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API object\n",
    "api = sly.Api(address, token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify input values\n",
    "\n",
    "Test that context (team / workspace / project) exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team: id=5, name=antonc\n",
      "Workspace: id=22, name=metrics\n",
      "Project: id=86, name=classification_metrics_demo_project\n"
     ]
    }
   ],
   "source": [
    "team = api.team.get_info_by_name(team_name)\n",
    "if team is None:\n",
    "    raise RuntimeError(\"Team {!r} not found\".format(team_name))\n",
    "\n",
    "workspace = api.workspace.get_info_by_name(team.id, workspace_name)\n",
    "if workspace is None:\n",
    "    raise RuntimeError(\"Workspace {!r} not found\".format(workspace_name))\n",
    "    \n",
    "project = api.project.get_info_by_name(workspace.id, project_name)\n",
    "if project is None:\n",
    "    raise RuntimeError(\"Project {!r} not found\".format(project_name))\n",
    "    \n",
    "print(\"Team: id={}, name={}\".format(team.id, team.name))\n",
    "print(\"Workspace: id={}, name={}\".format(workspace.id, workspace.name))\n",
    "print(\"Project: id={}, name={}\".format(project.id, project.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get source project meta\n",
    "\n",
    "Project meta contains information about classes and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_json = api.project.get_meta(project.id)\n",
    "meta = sly.ProjectMeta.from_json(meta_json)\n",
    "\n",
    "# check that all classes exist\n",
    "project_tags_names = list(tags_mapping.keys()) + list(tags_mapping.values())\n",
    "\n",
    "for tag_name in project_tags_names:\n",
    "    if not meta.tag_metas.has_key(tag_name):\n",
    "        raise RuntimeError(\"Class {!r} not found in source project {!r}\".format(class_name, project.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metric evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_evaluator = sly.ClassificationMetrics(tags_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over all images, and calculate metric by annotations pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: project = 'classification_metrics_demo_project', dataset = 'ds1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process annotations: 100%|██████████| 6/6 [00:00<00:00, 155.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset in api.dataset.get_list(project.id):\n",
    "    \n",
    "    # generate dataset name in destination project if it exists\n",
    "    print(\"Processing: project = {!r}, dataset = {!r}\".format(project.name, dataset.name), flush=True)\n",
    "    \n",
    "    images = api.image.get_list(dataset.id)\n",
    "    with tqdm(total=len(images), desc=\"Process annotations\") as progress_bar:\n",
    "        for batch in sly.batched(images):\n",
    "            image_ids = [image_info.id for image_info in batch]\n",
    "            ann_infos = api.annotation.download_batch(dataset.id, image_ids)\n",
    "            \n",
    "            for ann_info in ann_infos:\n",
    "                ann = sly.Annotation.from_json(ann_info.annotation, meta)\n",
    "                # We are using the same annotation on the both side of the metric computation\n",
    "                # (classes_mapping provides the corresponding classes that we will look for\n",
    "                # in the annotation), but it is also possible to use different annotations\n",
    "                # on left and right, e.g. to compare the source hand-labeled project to a\n",
    "                # neural netork inference result.\n",
    "                classification_evaluator.add_pair(ann, ann)\n",
    "            \n",
    "            progress_bar.update(len(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results with default logger\n",
    "\n",
    "The results are logged with the default Supervisely logger, so that the same code can be used in any custom plugin, and the log output would be nicely formatted in the task log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"message\": \"                                                                                \", \"timestamp\": \"2019-04-24T12:03:04.930Z\", \"level\": \"info\"}\n",
      "{\"message\": \"********************************************************************************\", \"timestamp\": \"2019-04-24T12:03:04.931Z\", \"level\": \"info\"}\n",
      "{\"message\": \"P = condition positive (the number of real positive cases in the data)          \", \"timestamp\": \"2019-04-24T12:03:04.932Z\", \"level\": \"info\"}\n",
      "{\"message\": \"N = condition negative (the number of real negative cases in the data)          \", \"timestamp\": \"2019-04-24T12:03:04.933Z\", \"level\": \"info\"}\n",
      "{\"message\": \"TP = True Positive prediction                                                   \", \"timestamp\": \"2019-04-24T12:03:04.933Z\", \"level\": \"info\"}\n",
      "{\"message\": \"TN = True Negative prediction                                                   \", \"timestamp\": \"2019-04-24T12:03:04.934Z\", \"level\": \"info\"}\n",
      "{\"message\": \"FP = False Positive prediction (Type I error)                                   \", \"timestamp\": \"2019-04-24T12:03:04.934Z\", \"level\": \"info\"}\n",
      "{\"message\": \"FN = False Negative prediction (Type II error)                                  \", \"timestamp\": \"2019-04-24T12:03:04.935Z\", \"level\": \"info\"}\n",
      "{\"message\": \"Accuracy = (TP + TN)/(TP + TN + FP + FN) = TRUE/TOTAL                           \", \"timestamp\": \"2019-04-24T12:03:04.935Z\", \"level\": \"info\"}\n",
      "{\"message\": \"Precision = TP / (TP + FP)                                                      \", \"timestamp\": \"2019-04-24T12:03:04.936Z\", \"level\": \"info\"}\n",
      "{\"message\": \"Recall = TP / (TP + FN)                                                         \", \"timestamp\": \"2019-04-24T12:03:04.936Z\", \"level\": \"info\"}\n",
      "{\"message\": \"F1-Measure = (2 * TP) / (2 * TP + FP + FN)                                      \", \"timestamp\": \"2019-04-24T12:03:04.937Z\", \"level\": \"info\"}\n",
      "{\"message\": \"********************************************************************************\", \"timestamp\": \"2019-04-24T12:03:04.937Z\", \"level\": \"info\"}\n",
      "{\"message\": \"                                                                                \", \"timestamp\": \"2019-04-24T12:03:04.944Z\", \"level\": \"info\"}\n",
      "{\"message\": \"1) kiwi <--> kiwi_pred:\", \"timestamp\": \"2019-04-24T12:03:04.944Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    accuracy        :   0.8333\", \"timestamp\": \"2019-04-24T12:03:04.945Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    precision       :   1.0000\", \"timestamp\": \"2019-04-24T12:03:04.945Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    recall          :   0.7500\", \"timestamp\": \"2019-04-24T12:03:04.946Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    F1-measure      :   0.8571\", \"timestamp\": \"2019-04-24T12:03:04.947Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    true-positive   :   3.0000\", \"timestamp\": \"2019-04-24T12:03:04.947Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    true-negative   :   2.0000\", \"timestamp\": \"2019-04-24T12:03:04.948Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    false-positive  :   0.0000\", \"timestamp\": \"2019-04-24T12:03:04.949Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    false-negative  :   1.0000\", \"timestamp\": \"2019-04-24T12:03:04.949Z\", \"level\": \"info\"}\n",
      "{\"message\": \"                                                                                \", \"timestamp\": \"2019-04-24T12:03:04.949Z\", \"level\": \"info\"}\n",
      "{\"message\": \"2) lemon <--> lemon_pred:\", \"timestamp\": \"2019-04-24T12:03:04.950Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    accuracy        :   0.8333\", \"timestamp\": \"2019-04-24T12:03:04.950Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    precision       :   0.6667\", \"timestamp\": \"2019-04-24T12:03:04.951Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    recall          :   1.0000\", \"timestamp\": \"2019-04-24T12:03:04.951Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    F1-measure      :   0.8000\", \"timestamp\": \"2019-04-24T12:03:04.952Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    true-positive   :   2.0000\", \"timestamp\": \"2019-04-24T12:03:04.952Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    true-negative   :   3.0000\", \"timestamp\": \"2019-04-24T12:03:04.957Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    false-positive  :   1.0000\", \"timestamp\": \"2019-04-24T12:03:04.963Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    false-negative  :   0.0000\", \"timestamp\": \"2019-04-24T12:03:04.964Z\", \"level\": \"info\"}\n",
      "{\"message\": \"                                                                                \", \"timestamp\": \"2019-04-24T12:03:04.965Z\", \"level\": \"info\"}\n",
      "{\"message\": \"Total values:\", \"timestamp\": \"2019-04-24T12:03:04.965Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    accuracy        :   0.8333\", \"timestamp\": \"2019-04-24T12:03:04.966Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    precision       :   0.8333\", \"timestamp\": \"2019-04-24T12:03:04.966Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    recall          :   0.8333\", \"timestamp\": \"2019-04-24T12:03:04.966Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    F1-measure      :   0.8333\", \"timestamp\": \"2019-04-24T12:03:04.967Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    true-positive   :   5.0000\", \"timestamp\": \"2019-04-24T12:03:04.967Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    true-negative   :   5.0000\", \"timestamp\": \"2019-04-24T12:03:04.968Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    false-positive  :   1.0000\", \"timestamp\": \"2019-04-24T12:03:04.968Z\", \"level\": \"info\"}\n",
      "{\"message\": \"    false-negative  :   1.0000\", \"timestamp\": \"2019-04-24T12:03:04.969Z\", \"level\": \"info\"}\n",
      "{\"message\": \"                                                                                \", \"timestamp\": \"2019-04-24T12:03:04.970Z\", \"level\": \"info\"}\n",
      "{\"message\": \"********************************************************************************\", \"timestamp\": \"2019-04-24T12:03:04.971Z\", \"level\": \"info\"}\n"
     ]
    }
   ],
   "source": [
    "classification_evaluator.log_total_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------------------+\n",
      "|     classes pair     |         metrics values         |\n",
      "+----------------------+--------------------------------+\n",
      "|  kiwi <-> kiwi_pred  |        true-positive: 3        |\n",
      "|                      |        true-negative: 2        |\n",
      "|                      |       false-positive: 0        |\n",
      "|                      |       false-negative: 1        |\n",
      "|                      |  accuracy: 0.8333333333333334  |\n",
      "|                      |         precision: 1.0         |\n",
      "|                      |          recall: 0.75          |\n",
      "|                      | F1-measure: 0.8571428571428571 |\n",
      "|                      |                                |\n",
      "| lemon <-> lemon_pred |        true-positive: 2        |\n",
      "|                      |        true-negative: 3        |\n",
      "|                      |       false-positive: 1        |\n",
      "|                      |       false-negative: 0        |\n",
      "|                      |  accuracy: 0.8333333333333334  |\n",
      "|                      | precision: 0.6666666666666666  |\n",
      "|                      |          recall: 1.0           |\n",
      "|                      |        F1-measure: 0.8         |\n",
      "|                      |                                |\n",
      "|        TOTAL         |        true-positive: 5        |\n",
      "|                      |        true-negative: 5        |\n",
      "|                      |       false-positive: 1        |\n",
      "|                      |       false-negative: 1        |\n",
      "|                      |  accuracy: 0.8333333333333334  |\n",
      "|                      | precision: 0.8333333333333334  |\n",
      "|                      |   recall: 0.8333333333333334   |\n",
      "|                      | F1-measure: 0.8333333333333334 |\n",
      "|                      |                                |\n",
      "+----------------------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Metrics for each pair of classes separately.\n",
    "per_class_metrics = classification_evaluator.get_metrics()\n",
    "\n",
    "# Metrics aggregated over all pairs of classes from classes_mapping\n",
    "total_metrics = classification_evaluator.get_total_metrics()\n",
    "\n",
    "table = PrettyTable([\"classes pair\", \"metrics values\"])\n",
    "\n",
    "def build_values_text(values):\n",
    "    return ''.join(\n",
    "        \"{}: {}\\n\".format(metrics_name, value)\n",
    "        for metrics_name, value in values.items())\n",
    "    \n",
    "for gt_class, metric_values in per_class_metrics.items():\n",
    "    pair_text = \"{} <-> {}\".format(gt_class, tags_mapping[gt_class])\n",
    "    table.add_row([pair_text, build_values_text(metric_values)])\n",
    "\n",
    "table.add_row([\"TOTAL\", build_values_text(total_metrics)])\n",
    "print(table.get_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
